{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert documents to Excel sheet\n",
    "- Collect list of Word documents\n",
    "- For each Word document:\n",
    "1) Extract all text\n",
    "2) Combine all text to a single string (remove excess whitespace first)\n",
    "3) Break by keywords STUDENT and CHATGPT\n",
    "4) Return dataframe with single row per student response\n",
    "5) Run word count on student and ChatGPT responses\n",
    "- Combine all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:34: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:34: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_24596\\3777762459.py:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  {'Html': '<div\\sclass=.+>', 'Replace with': ''},\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_24596\\3777762459.py:10: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  {'Html': '<span\\sclass=.+><span\\sdata-offset-key.+>', 'Replace with': ''},\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_24596\\3777762459.py:11: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  {'Html': '<span\\sdata-offset-key.+>', 'Replace with': ''},\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_24596\\3777762459.py:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  {'Html': '<span\\sstyle=.+>', 'Replace with': ''},\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_24596\\3777762459.py:15: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  {'Html': 'https://.+\\s', 'Replace with': '[url]'},\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_24596\\3777762459.py:34: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  equation_regex='<img\\sclass=.equation_image.+?>'\n"
     ]
    }
   ],
   "source": [
    "replacement_list=[\n",
    "    {'Html': '\\n', 'Replace with': ''},\n",
    "    {'Html': '<strong>', 'Replace with': ''},\n",
    "    {'Html': '</strong>', 'Replace with': ''}, \n",
    "    {'Html': '<em>', 'Replace with': ''},\n",
    "    {'Html': '</em>', 'Replace with': ''},\n",
    "    {'Html': '&nbsp;', 'Replace with': ' '}, \n",
    "    {'Html': '<div>', 'Replace with': ''},\n",
    "    {'Html': '<div\\sclass=.+>', 'Replace with': ''},\n",
    "    {'Html': '<span\\sclass=.+><span\\sdata-offset-key.+>', 'Replace with': ''},\n",
    "    {'Html': '<span\\sdata-offset-key.+>', 'Replace with': ''},\n",
    "    {'Html': '<span\\sstyle=.+>', 'Replace with': ''},\n",
    "    {'Html': '</div>', 'Replace with': ''},\n",
    "    #{'Html': '<img.+>', 'Replace with': '[image]'}, Removes equations. \n",
    "    {'Html': 'https://.+\\s', 'Replace with': '[url]'},\n",
    "    {'Html': '&amp;', 'Replace with': '&'},\n",
    "    {'Html': '<script.+</script>', 'Replace with': ''},\n",
    "    {'Html': '<ol>', 'Replace with': ''},\n",
    "    {'Html': '</ol>', 'Replace with': ''},\n",
    "    {'Html': '<ul>', 'Replace with': ''},\n",
    "    {'Html': '</ul>', 'Replace with': ''},\n",
    "    {'Html': '<p>', 'Replace with': ''}, \n",
    "    {'Html': '</p>', 'Replace with': ' '}, \n",
    "    {'Html': '<li>', 'Replace with': ''}, # Special case \n",
    "    {'Html': '<sup>', 'Replace with': '^'}, \n",
    "    {'Html': '</sup>', 'Replace with': ''},\n",
    "    {'Html': '\\\\n', 'Replace with': ''},\n",
    "    {'Html': '\\\\\\\\:', 'Replace with': ''},\n",
    "]\n",
    "\n",
    "def extract_equation(entry):\n",
    "    match_list=re.findall('<p>(.*)</p>', entry)\n",
    "    extract_equation_list=[]\n",
    "    equation_regex='<img\\sclass=.equation_image.+?>'\n",
    "    for sentence in match_list:\n",
    "        if re.findall(equation_regex, sentence)!=[]:\n",
    "            split_without_equation=re.split(equation_regex, sentence)\n",
    "            raw_equation_list=re.findall(equation_regex, sentence)\n",
    "            clean_equation_list=[]\n",
    "            for raw_equation in raw_equation_list:\n",
    "                # First try to extact the exact equation display\n",
    "                try:\n",
    "                    math_to_display=re.search('data-equation-content=\".*?\"', raw_equation).group()\n",
    "                    cleaned_math=re.sub('data-equation-content=\"', '', math_to_display)\n",
    "                    cleaned_math=re.sub('\"', '', cleaned_math)\n",
    "                    clean_equation_list.append(cleaned_math)\n",
    "                # If an error occurs (such as not finding data-equation-content) substitute for a generic statement\n",
    "                except:\n",
    "                    clean_equation_list.append('[equation_image]')\n",
    "            clean_sentence=split_without_equation.pop(0)\n",
    "            while len(clean_equation_list)!=0:\n",
    "                clean_sentence+=clean_equation_list.pop(0)\n",
    "                clean_sentence+=split_without_equation.pop(0)\n",
    "            extract_equation_list.append(clean_sentence)\n",
    "        else:\n",
    "            extract_equation_list.append(sentence)\n",
    "    final_string = ' '.join(extract_equation_list)\n",
    "    final_string = re.sub('&nbsp;', '', final_string)\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_docx(document_opened):\n",
    "    # Extract text from document into list of paragraphs\n",
    "    list_of_paragraphs = []\n",
    "    for para in document_opened.paragraphs:\n",
    "        list_of_paragraphs.append(para.text)\n",
    "    # Combine into single string\n",
    "    single_string = ' '.join(list_of_paragraphs)\n",
    "    # Split by STUDENT and CHATGPT\n",
    "    full_split = re.split('STUDENT | CHATGPT', single_string)\n",
    "    clean_split = [string for string in full_split if len(string) > 0]\n",
    "    # Create list of dicts for each response\n",
    "    list_of_response_dicts = []\n",
    "    while len(clean_split) > 1: \n",
    "        temp_dict = {\n",
    "             \"Student Response\": clean_split.pop(0),\n",
    "             \"ChatGPT Feedback\": clean_split.pop(0)\n",
    "        }\n",
    "        list_of_response_dicts.append(temp_dict)\n",
    "    # Create Dataframe from list\n",
    "    df_responses = pd.DataFrame(list_of_response_dicts)\n",
    "    return df_responses\n",
    "\n",
    "def clean_raw_html(entry):\n",
    "    revised_entry = extract_equation(entry)\n",
    "    for replacement_dict in replacement_list:\n",
    "        revised_entry = re.sub(replacement_dict['Html'], replacement_dict['Replace with'], revised_entry)\n",
    "    return revised_entry\n",
    "\n",
    "def extract_text_from_xlsx(document_opened):\n",
    "    df = pd.read_excel(document_opened, skiprows=1)\n",
    "    df['Student Response'] = df['Raw HTML Response'].apply(clean_raw_html)\n",
    "    df['ChatGPT Feedback'] = df['ChatGPT Raw Feedback'].apply(clean_raw_html)\n",
    "    return df\n",
    "\n",
    "def define_sentence_length(list_of_substrings):\n",
    "    if type(list_of_substrings) != type([]): # Returns 0 for nan values, which str.split() returns for empty cells\n",
    "        return 0\n",
    "    else:\n",
    "        return len(list_of_substrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir=os.getcwd()\n",
    "if os.name == 'nt':\n",
    "    path_break='\\\\'\n",
    "else:\n",
    "    path_break='/'\n",
    "\n",
    "# Collects names of files in the Raw_Files folders. \n",
    "all_docx_files = []\n",
    "all_xlsx_files = []\n",
    "for file in glob.glob(f'{base_dir}{path_break}Raw_Files{path_break}*'):\n",
    "    if '$' not in file:\n",
    "        if 'xlsx' in file:\n",
    "            all_xlsx_files.append(file)\n",
    "        elif 'docx' in file:\n",
    "            all_docx_files.append(file)\n",
    "\n",
    "list_of_dfs = []\n",
    "for file_name in all_docx_files:\n",
    "    temp_df = extract_text_from_docx(Document(file_name))\n",
    "    root_name = f'{base_dir}{path_break}Raw_Files{path_break}'\n",
    "    short_file_name = file_name[len(root_name):]\n",
    "    list_of_info = re.split('-', short_file_name)\n",
    "\n",
    "    temp_df['Instructor'] = list_of_info[0].strip()\n",
    "    temp_df['Course'] = list_of_info[1].strip()\n",
    "    temp_df['Response Word Count'] = temp_df['Student Response'].str.split().map(define_sentence_length) \n",
    "\n",
    "    list_of_dfs.append(temp_df)\n",
    "\n",
    "for file_name in all_xlsx_files:\n",
    "    temp_df = extract_text_from_xlsx(file_name)\n",
    "    root_name = f'{base_dir}{path_break}Raw_Files{path_break}'\n",
    "    short_file_name = file_name[len(root_name):]\n",
    "    list_of_info = re.split('-', short_file_name)\n",
    "\n",
    "    temp_df['Instructor'] = list_of_info[0].strip()\n",
    "    temp_df['Course'] = list_of_info[1].strip()\n",
    "    temp_df['Response Word Count'] = temp_df['Student Response'].str.split().map(define_sentence_length)\n",
    "    \n",
    "    list_of_dfs.append(temp_df)\n",
    "\n",
    "final_df = pd.concat(list_of_dfs)\n",
    "final_df.to_excel('combined_responses.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_excel('./Raw_Files/Darryl - MATH 111 - Processed.xlsx', skiprows=1)\n",
    "test_df['clean_responses'] = test_df['Raw HTML Response'].apply(clean_raw_html)\n",
    "test_df.to_excel('check_test.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: ChatGPT scores and whether the instructor re-prompted ChatGPT are manually added to \"combined_responses\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
